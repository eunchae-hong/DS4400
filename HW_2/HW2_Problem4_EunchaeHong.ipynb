{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246cc7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS4400 HW 2\n",
    "# Problem 4: Polynomial Regression\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "\n",
    "house_data = pd.read_csv(\"kc_house_data.csv\")\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14686615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation copied over from problem 3\n",
    "def lin_regress_train(X, y):\n",
    "    ''' function that implements the closed form solution for multiple linear regression and returns theta\n",
    "        uses np.linalg.pinv instead of inv because of the lecture slides '''\n",
    "    theta = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "def predict_response(X, theta):\n",
    "    ''' function that returns the predicted responses from the multiple linear regression '''\n",
    "    response = X @ theta\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab4afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider a feature X, a response variable Y, and N samples of training data\n",
    "def polynomial_features(X, p):\n",
    "    ''' function that takes in the number of features to return polynomial feature matrix '''\n",
    "    N = X.shape[0]\n",
    "    X_poly = np.ones((N, p + 1))\n",
    "\n",
    "    for i in range(1, p + 1):\n",
    "        X_poly[:, i] = X[:, 0] ** i\n",
    "\n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5314642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Degree (p)  Train MSE  Train R Squared     Test MSE  Test R Squared\n",
      "0           1   57947.53             0.50     88575.98            0.47\n",
      "1           5  129385.49            -0.12  13690251.07          -81.11\n",
      "2          10  125593.52            -0.09  13435896.67          -79.59\n",
      "3          15  123654.46            -0.07  13415428.70          -79.46\n"
     ]
    }
   ],
   "source": [
    "# considering the problem with X = sqft_living\n",
    "\n",
    "# get training and testing data for column sqft_living\n",
    "X_train = train_data[['sqft_living']].values\n",
    "y_train = train_data['price'].div(1000).values.reshape(-1, 1)\n",
    "\n",
    "X_test = test_data[['sqft_living']].values\n",
    "y_test = test_data['price'].div(1000).values.reshape(-1, 1)\n",
    "\n",
    "# intialize empty list for the results\n",
    "metric_results = []\n",
    "\n",
    "# choose three different values for p >= 5 (5, 10, 15)\n",
    "for p in [1, 5, 10, 15]:\n",
    "    # create the polynomial matrices\n",
    "    X_train_poly = polynomial_features(X_train, p)\n",
    "    X_test_poly = polynomial_features(X_test, p)\n",
    "\n",
    "    # train the data using lin_regress_train function\n",
    "    theta = lin_regress_train(X_train_poly, y_train)\n",
    "\n",
    "    y_train_pred = predict_response(X_train_poly, theta)\n",
    "    y_test_pred = predict_response(X_test_poly, theta)\n",
    "\n",
    "    # get the MSE and r squared metrics for training and testing\n",
    "    train_mse = round(mean_squared_error(y_train, y_train_pred), 2)\n",
    "    train_r2 = round(r2_score(y_train, y_train_pred), 2)\n",
    "\n",
    "    test_mse = round(mean_squared_error(y_test, y_test_pred), 2)\n",
    "    test_r2 = round(r2_score(y_test, y_test_pred), 2)\n",
    "\n",
    "    metric_results.append([p, train_mse, train_r2, test_mse, test_r2])\n",
    "\n",
    "metric_table = pd.DataFrame(\n",
    "    metric_results,\n",
    "    columns = [\"Degree (p)\", \"Train MSE\", \"Train R Squared\", \"Test MSE\", \"Test R Squared\"]\n",
    ")\n",
    "print(metric_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c664ddb2",
   "metadata": {},
   "source": [
    "Discuss your observations on how the MSE and $R^2$ metrics change with the degree of the polynomial.\n",
    "\n",
    "As the degree of the polynomial increases for both the training and testing MSE the value increases from  p = 1 to p = 5, but after 5 the values begin to decrease. For $R^2$ the values decrease from p = 1 to p = 5, but after they began to slowly increase, following an opposite pattern then the MSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
